{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Matemática Para Machine Learning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudo de Caso 5 - Compreendendo Como Funciona o Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4 - Otimização com Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent (SGD) é uma versão de Gradient Descent, onde em cada passagem para a frente, obtemos um lote de dados com amostras aleatórias do conjunto de dados total. Aqui onde entra em cena o batch_size. Esse é o tamanho do lote. Idealmente, todo o conjunto de dados seria alimentado na rede neural em cada passagem para a frente, mas na prática isso acaba não sendo possível, devido a restrições de memória. SGD é uma aproximação de Gradient Descent, quanto mais lotes processados pela rede neural, melhor será a aproximação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma implementação do SGD envolve:\n",
    "\n",
    "1. Gerar lotes de dados de amostras aleatórias do conjunto de dados total.\n",
    "\n",
    "2. Executar a rede para frente (Forward Pass) e para trás (Backward pass) para calcular o gradiente (com dados de (1)).\n",
    "\n",
    "3. Aplicar a atualização de descida do gradiente.\n",
    "\n",
    "4. Repetir as etapas 1-3 até a convergência ou o loop for parado por outro mecanismo (como o número de épocas, por exemplo).\n",
    "\n",
    "Se tudo correr bem, a perda da rede vai diminuindo, indicando pesos e bias mais úteis ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuronio:\n",
    "    \"\"\"\n",
    "    Classe base para os nós da rede.\n",
    "\n",
    "    Argumentos:\n",
    "\n",
    "        \"nodes_entrada\": Uma lista de nós com arestas para este nó.\n",
    "    \"\"\"\n",
    "    def __init__(self, nodes_entrada = []):\n",
    "        \"\"\"\n",
    "        O construtor do nó (é executado quando o objeto é instanciado). \n",
    "        Define propriedades que podem ser usadas por todos os nós.\n",
    "        \"\"\"\n",
    "        # Lista de nós com arestas para este nó.\n",
    "        self.nodes_entrada = nodes_entrada\n",
    "        \n",
    "        # Lista de nós para os quais este nó gera saída.\n",
    "        self.nodes_saida = []\n",
    "        \n",
    "        # O valor calculado por este nó. É definido executando o método forward().\n",
    "        self.valor = None\n",
    "        \n",
    "        # Este objeto é um dicionário com pares chaves/valor entre {} \n",
    "        # As chaves (keys) são os inputs para este nó e o valores (values) são as paciais deste nó em relação ao input.\n",
    "        self.gradientes = {}\n",
    "        \n",
    "        # Configuramos este nó como um nó de saída para todos os nós de entrada.\n",
    "        for n in nodes_entrada:\n",
    "            n.nodes_saida.append(self)\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Todo o nó que usar essa classe como uma classe base, precisa definir seu próprio método \"forward\".\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Todo o nó que usar essa classe como uma classe base, precisa definir seu próprio método \"backward\".\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "class Input(Neuronio):\n",
    "    \"\"\"\n",
    "    Input genérico para a rede.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # O construtor da classe base deve ser executado para configurar todas as propriedades aqui.\n",
    "        #\n",
    "        # A propriedade mais importante de Input é valor.\n",
    "        # self.valor é definido na função topological_sort().\n",
    "        Neuronio.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Nada a ser feito aqui.\n",
    "        pass\n",
    "\n",
    "    def backward(self):\n",
    "        # Um nó de Input não possui entradas (pois ele já é a entrada) e assim o gradiente (derivada) é zero.\n",
    "        # A palavra reservada \"self\", é referência para este objeto.\n",
    "        self.gradientes = {self: 0}\n",
    "        \n",
    "        # Pesos e bias podem ser inputs, assim precisamos somar o gradiente de outros gradientes de saída\n",
    "        for n in self.nodes_saida:\n",
    "            self.gradientes[self] += n.gradientes[self]\n",
    "            \n",
    "\n",
    "class Linear(Neuronio):\n",
    "    \"\"\"\n",
    "    Representa um nó que realiza transformação linear.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, W, b):\n",
    "        # O construtor da classe base (nó). \n",
    "        # Pesos e bias são tratados como nós de entrada (nodes_entrada).\n",
    "        Neuronio.__init__(self, [X, W, b])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Executa a matemática por trás da transformação linear.\n",
    "        \"\"\"\n",
    "        X = self.nodes_entrada[0].valor\n",
    "        W = self.nodes_entrada[1].valor\n",
    "        b = self.nodes_entrada[2].valor\n",
    "        self.valor = np.dot(X, W) + b\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Calcula o gradiente com base nos valores de saída.\n",
    "        \"\"\"\n",
    "        # Inicializa um parcial para cada um dos nodes_entrada.\n",
    "        self.gradientes = {n: np.zeros_like(n.valor) for n in self.nodes_entrada}\n",
    "        \n",
    "        # Ciclo através dos outputs. \n",
    "        # O gradiente mudará dependendo de cada output, assim os gradientes são somados sobre todos os outputs.\n",
    "        for n in self.nodes_saida:\n",
    "            \n",
    "            # Obtendo parcial da perda em relação a este nó.\n",
    "            grad_cost = n.gradientes[self]\n",
    "            \n",
    "            # Definindo o parcial da perda em relação às entradas deste nó.\n",
    "            self.gradientes[self.nodes_entrada[0]] += np.dot(grad_cost, self.nodes_entrada[1].valor.T)\n",
    "            \n",
    "            # Definindo o parcial da perda em relação aos pesos deste nó.\n",
    "            self.gradientes[self.nodes_entrada[1]] += np.dot(self.nodes_entrada[0].valor.T, grad_cost)\n",
    "            \n",
    "            # Definindo o parcial da perda em relação ao bias deste nó.\n",
    "            self.gradientes[self.nodes_entrada[2]] += np.sum(grad_cost, axis = 0, keepdims = False)\n",
    "\n",
    "\n",
    "class Sigmoid(Neuronio):\n",
    "    \"\"\"\n",
    "    Representa o nó da função de ativação Sigmoid.\n",
    "    \"\"\"\n",
    "    def __init__(self, node):\n",
    "        # O construtor da classe base.\n",
    "        Neuronio.__init__(self, [node])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        Este método é separado do `forward` porque ele também será usado com \"backward\".\n",
    "\n",
    "        `x`: Um array Numpy.\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Executa a função _sigmoid e define a variável self.valor\n",
    "        \"\"\"\n",
    "        input_value = self.nodes_entrada[0].valor\n",
    "        self.valor = self._sigmoid(input_value)\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Calcula o gradiente usando a derivada da função sigmoid \n",
    "        \n",
    "        O método backward da classe Sigmoid, soma as derivadas (é uma derivada normal quando há apenas uma variável) \n",
    "        em relação à única entrada sobre todos os nós de saída.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Inicializa os gradientes com zero.\n",
    "        self.gradientes = {n: np.zeros_like(n.valor) for n in self.nodes_entrada}\n",
    "        \n",
    "        # Soma a parcial em relação ao input sobre todos os outputs.\n",
    "        for n in self.nodes_saida:\n",
    "            grad_cost = n.gradientes[self]\n",
    "            sigmoid = self.valor\n",
    "            self.gradientes[self.nodes_entrada[0]] += sigmoid * (1 - sigmoid) * grad_cost\n",
    "\n",
    "\n",
    "class MSE(Neuronio):\n",
    "    def __init__(self, y, a):\n",
    "        \"\"\"\n",
    "        Função de custo para calcular o erro médio quadrático.\n",
    "        Deve ser usado como último nó da rede.\n",
    "        \"\"\"\n",
    "        # Chamada ao construtor da classe base.\n",
    "        Neuronio.__init__(self, [y, a])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Calcula o erro médio ao quadrado.\n",
    "        \"\"\"\n",
    "        # Fazemos o reshape para evitar possíveis problemas nas operações de matrizes/vetores \n",
    "        #\n",
    "        # Convertendo os 2 arrays (3,1) garantimos que o resultado será (3,1) e, assim, \n",
    "        # teremos uma subtração elementwise.\n",
    "        y = self.nodes_entrada[0].valor.reshape(-1, 1)\n",
    "        a = self.nodes_entrada[1].valor.reshape(-1, 1)\n",
    "\n",
    "        self.m = self.nodes_entrada[0].valor.shape[0]\n",
    "        \n",
    "        # Salva o output computado para o backward pass.\n",
    "        self.diff = y - a\n",
    "        self.valor = np.mean(self.diff**2)\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Calcula o gradiente do custo.\n",
    "        \"\"\"\n",
    "        self.gradientes[self.nodes_entrada[0]] = (2 / self.m) * self.diff\n",
    "        self.gradientes[self.nodes_entrada[1]] = (-2 / self.m) * self.diff\n",
    "\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Classifica os nós em ordem topológica usando o Algoritmo de Kahn.\n",
    "\n",
    "    `Feed_dict`: um dicionário em que a chave é um nó `Input` e o valor é o respectivo feed de valor para esse nó.\n",
    "\n",
    "    Retorna uma lista de nós ordenados.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.nodes_saida:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.valor = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.nodes_saida:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_and_backward(graph):\n",
    "    \"\"\"\n",
    "    Executa uma passagem para a frente e uma passagem para trás através de uma lista de nós ordenados.\n",
    "\n",
    "     Argumentos:\n",
    "\n",
    "         `Graph`: O resultado de `topological_sort`.\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "\n",
    "    # Backward pass\n",
    "    # O valor negativo no slice permite fazer uma cópia da mesma lista na ordem inversa.\n",
    "    for n in graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "\n",
    "def sgd_update(params, learning_rate = 1e-2):\n",
    "    \"\"\"\n",
    "    Atualiza o valor de cada parâmetro treinável com o SGD.\n",
    "\n",
    "    Argumentos:\n",
    "\n",
    "         `Trainables`: uma lista de nós `Input` que representam pesos / bias.\n",
    "         `Learning_rate`: a taxa de aprendizado.\n",
    "    \"\"\"\n",
    "    # Executa o SGD\n",
    "    #\n",
    "    # Loop sobre todos os parâmetros\n",
    "    for t in params:\n",
    "        # Alterar o valor do parâmetro, subtraindo a taxa de aprendizado \n",
    "        # multiplicado pela parte do custo em relação a esse parâmetro\n",
    "        partial = t.gradientes[t]\n",
    "        t.valor -= learning_rate * partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executando o Grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "poch: 201, Custo: 5.620\n",
      "Epoch: 202, Custo: 4.689\n",
      "Epoch: 203, Custo: 5.677\n",
      "Epoch: 204, Custo: 4.830\n",
      "Epoch: 205, Custo: 5.434\n",
      "Epoch: 206, Custo: 6.139\n",
      "Epoch: 207, Custo: 5.118\n",
      "Epoch: 208, Custo: 5.322\n",
      "Epoch: 209, Custo: 5.555\n",
      "Epoch: 210, Custo: 6.070\n",
      "Epoch: 211, Custo: 5.120\n",
      "Epoch: 212, Custo: 4.638\n",
      "Epoch: 213, Custo: 4.945\n",
      "Epoch: 214, Custo: 4.147\n",
      "Epoch: 215, Custo: 4.655\n",
      "Epoch: 216, Custo: 5.772\n",
      "Epoch: 217, Custo: 5.347\n",
      "Epoch: 218, Custo: 4.188\n",
      "Epoch: 219, Custo: 4.383\n",
      "Epoch: 220, Custo: 5.699\n",
      "Epoch: 221, Custo: 4.730\n",
      "Epoch: 222, Custo: 4.112\n",
      "Epoch: 223, Custo: 6.280\n",
      "Epoch: 224, Custo: 5.209\n",
      "Epoch: 225, Custo: 5.737\n",
      "Epoch: 226, Custo: 4.899\n",
      "Epoch: 227, Custo: 5.197\n",
      "Epoch: 228, Custo: 5.195\n",
      "Epoch: 229, Custo: 4.890\n",
      "Epoch: 230, Custo: 4.540\n",
      "Epoch: 231, Custo: 4.572\n",
      "Epoch: 232, Custo: 4.825\n",
      "Epoch: 233, Custo: 4.477\n",
      "Epoch: 234, Custo: 5.039\n",
      "Epoch: 235, Custo: 4.120\n",
      "Epoch: 236, Custo: 4.973\n",
      "Epoch: 237, Custo: 4.703\n",
      "Epoch: 238, Custo: 5.648\n",
      "Epoch: 239, Custo: 4.784\n",
      "Epoch: 240, Custo: 5.010\n",
      "Epoch: 241, Custo: 5.624\n",
      "Epoch: 242, Custo: 5.026\n",
      "Epoch: 243, Custo: 5.271\n",
      "Epoch: 244, Custo: 4.984\n",
      "Epoch: 245, Custo: 4.196\n",
      "Epoch: 246, Custo: 5.265\n",
      "Epoch: 247, Custo: 4.599\n",
      "Epoch: 248, Custo: 4.400\n",
      "Epoch: 249, Custo: 4.724\n",
      "Epoch: 250, Custo: 5.474\n",
      "Epoch: 251, Custo: 4.585\n",
      "Epoch: 252, Custo: 4.447\n",
      "Epoch: 253, Custo: 3.792\n",
      "Epoch: 254, Custo: 4.220\n",
      "Epoch: 255, Custo: 4.730\n",
      "Epoch: 256, Custo: 4.871\n",
      "Epoch: 257, Custo: 6.661\n",
      "Epoch: 258, Custo: 3.957\n",
      "Epoch: 259, Custo: 4.376\n",
      "Epoch: 260, Custo: 4.791\n",
      "Epoch: 261, Custo: 5.005\n",
      "Epoch: 262, Custo: 4.934\n",
      "Epoch: 263, Custo: 4.218\n",
      "Epoch: 264, Custo: 4.938\n",
      "Epoch: 265, Custo: 5.144\n",
      "Epoch: 266, Custo: 4.684\n",
      "Epoch: 267, Custo: 4.734\n",
      "Epoch: 268, Custo: 5.192\n",
      "Epoch: 269, Custo: 4.748\n",
      "Epoch: 270, Custo: 4.695\n",
      "Epoch: 271, Custo: 5.306\n",
      "Epoch: 272, Custo: 4.042\n",
      "Epoch: 273, Custo: 4.493\n",
      "Epoch: 274, Custo: 4.076\n",
      "Epoch: 275, Custo: 4.507\n",
      "Epoch: 276, Custo: 5.619\n",
      "Epoch: 277, Custo: 4.205\n",
      "Epoch: 278, Custo: 3.979\n",
      "Epoch: 279, Custo: 4.634\n",
      "Epoch: 280, Custo: 4.277\n",
      "Epoch: 281, Custo: 4.165\n",
      "Epoch: 282, Custo: 5.329\n",
      "Epoch: 283, Custo: 4.556\n",
      "Epoch: 284, Custo: 4.777\n",
      "Epoch: 285, Custo: 5.404\n",
      "Epoch: 286, Custo: 4.688\n",
      "Epoch: 287, Custo: 4.670\n",
      "Epoch: 288, Custo: 5.143\n",
      "Epoch: 289, Custo: 5.263\n",
      "Epoch: 290, Custo: 4.963\n",
      "Epoch: 291, Custo: 4.433\n",
      "Epoch: 292, Custo: 4.913\n",
      "Epoch: 293, Custo: 4.986\n",
      "Epoch: 294, Custo: 4.700\n",
      "Epoch: 295, Custo: 4.476\n",
      "Epoch: 296, Custo: 4.947\n",
      "Epoch: 297, Custo: 4.469\n",
      "Epoch: 298, Custo: 4.784\n",
      "Epoch: 299, Custo: 4.133\n",
      "Epoch: 300, Custo: 4.691\n",
      "Epoch: 301, Custo: 4.887\n",
      "Epoch: 302, Custo: 4.851\n",
      "Epoch: 303, Custo: 4.204\n",
      "Epoch: 304, Custo: 4.548\n",
      "Epoch: 305, Custo: 4.672\n",
      "Epoch: 306, Custo: 4.564\n",
      "Epoch: 307, Custo: 3.951\n",
      "Epoch: 308, Custo: 4.775\n",
      "Epoch: 309, Custo: 4.979\n",
      "Epoch: 310, Custo: 4.140\n",
      "Epoch: 311, Custo: 4.670\n",
      "Epoch: 312, Custo: 4.413\n",
      "Epoch: 313, Custo: 4.152\n",
      "Epoch: 314, Custo: 4.907\n",
      "Epoch: 315, Custo: 4.524\n",
      "Epoch: 316, Custo: 5.043\n",
      "Epoch: 317, Custo: 6.211\n",
      "Epoch: 318, Custo: 4.401\n",
      "Epoch: 319, Custo: 4.040\n",
      "Epoch: 320, Custo: 4.072\n",
      "Epoch: 321, Custo: 4.492\n",
      "Epoch: 322, Custo: 3.980\n",
      "Epoch: 323, Custo: 4.564\n",
      "Epoch: 324, Custo: 4.531\n",
      "Epoch: 325, Custo: 5.162\n",
      "Epoch: 326, Custo: 4.892\n",
      "Epoch: 327, Custo: 3.673\n",
      "Epoch: 328, Custo: 5.030\n",
      "Epoch: 329, Custo: 4.672\n",
      "Epoch: 330, Custo: 4.344\n",
      "Epoch: 331, Custo: 4.390\n",
      "Epoch: 332, Custo: 4.744\n",
      "Epoch: 333, Custo: 4.124\n",
      "Epoch: 334, Custo: 5.209\n",
      "Epoch: 335, Custo: 5.049\n",
      "Epoch: 336, Custo: 4.272\n",
      "Epoch: 337, Custo: 4.741\n",
      "Epoch: 338, Custo: 4.496\n",
      "Epoch: 339, Custo: 4.223\n",
      "Epoch: 340, Custo: 5.300\n",
      "Epoch: 341, Custo: 4.346\n",
      "Epoch: 342, Custo: 4.597\n",
      "Epoch: 343, Custo: 4.907\n",
      "Epoch: 344, Custo: 4.501\n",
      "Epoch: 345, Custo: 4.588\n",
      "Epoch: 346, Custo: 4.798\n",
      "Epoch: 347, Custo: 3.885\n",
      "Epoch: 348, Custo: 4.297\n",
      "Epoch: 349, Custo: 3.837\n",
      "Epoch: 350, Custo: 4.412\n",
      "Epoch: 351, Custo: 4.048\n",
      "Epoch: 352, Custo: 4.396\n",
      "Epoch: 353, Custo: 4.210\n",
      "Epoch: 354, Custo: 5.853\n",
      "Epoch: 355, Custo: 3.993\n",
      "Epoch: 356, Custo: 5.889\n",
      "Epoch: 357, Custo: 4.328\n",
      "Epoch: 358, Custo: 3.855\n",
      "Epoch: 359, Custo: 4.600\n",
      "Epoch: 360, Custo: 4.444\n",
      "Epoch: 361, Custo: 5.405\n",
      "Epoch: 362, Custo: 4.999\n",
      "Epoch: 363, Custo: 4.169\n",
      "Epoch: 364, Custo: 4.419\n",
      "Epoch: 365, Custo: 4.708\n",
      "Epoch: 366, Custo: 4.388\n",
      "Epoch: 367, Custo: 4.480\n",
      "Epoch: 368, Custo: 4.678\n",
      "Epoch: 369, Custo: 4.207\n",
      "Epoch: 370, Custo: 4.730\n",
      "Epoch: 371, Custo: 4.208\n",
      "Epoch: 372, Custo: 5.409\n",
      "Epoch: 373, Custo: 4.340\n",
      "Epoch: 374, Custo: 3.790\n",
      "Epoch: 375, Custo: 4.615\n",
      "Epoch: 376, Custo: 5.050\n",
      "Epoch: 377, Custo: 3.956\n",
      "Epoch: 378, Custo: 3.419\n",
      "Epoch: 379, Custo: 4.101\n",
      "Epoch: 380, Custo: 4.292\n",
      "Epoch: 381, Custo: 4.206\n",
      "Epoch: 382, Custo: 4.157\n",
      "Epoch: 383, Custo: 5.068\n",
      "Epoch: 384, Custo: 4.732\n",
      "Epoch: 385, Custo: 4.278\n",
      "Epoch: 386, Custo: 4.571\n",
      "Epoch: 387, Custo: 4.513\n",
      "Epoch: 388, Custo: 3.931\n",
      "Epoch: 389, Custo: 3.959\n",
      "Epoch: 390, Custo: 4.364\n",
      "Epoch: 391, Custo: 4.368\n",
      "Epoch: 392, Custo: 3.813\n",
      "Epoch: 393, Custo: 4.498\n",
      "Epoch: 394, Custo: 4.152\n",
      "Epoch: 395, Custo: 4.278\n",
      "Epoch: 396, Custo: 4.669\n",
      "Epoch: 397, Custo: 4.449\n",
      "Epoch: 398, Custo: 4.524\n",
      "Epoch: 399, Custo: 4.516\n",
      "Epoch: 400, Custo: 4.623\n",
      "Epoch: 401, Custo: 4.885\n",
      "Epoch: 402, Custo: 4.415\n",
      "Epoch: 403, Custo: 3.723\n",
      "Epoch: 404, Custo: 4.680\n",
      "Epoch: 405, Custo: 4.115\n",
      "Epoch: 406, Custo: 3.569\n",
      "Epoch: 407, Custo: 4.762\n",
      "Epoch: 408, Custo: 3.375\n",
      "Epoch: 409, Custo: 5.095\n",
      "Epoch: 410, Custo: 4.218\n",
      "Epoch: 411, Custo: 2.995\n",
      "Epoch: 412, Custo: 4.257\n",
      "Epoch: 413, Custo: 4.031\n",
      "Epoch: 414, Custo: 3.901\n",
      "Epoch: 415, Custo: 3.820\n",
      "Epoch: 416, Custo: 4.493\n",
      "Epoch: 417, Custo: 4.520\n",
      "Epoch: 418, Custo: 4.989\n",
      "Epoch: 419, Custo: 4.407\n",
      "Epoch: 420, Custo: 4.314\n",
      "Epoch: 421, Custo: 4.143\n",
      "Epoch: 422, Custo: 3.676\n",
      "Epoch: 423, Custo: 3.340\n",
      "Epoch: 424, Custo: 3.820\n",
      "Epoch: 425, Custo: 4.819\n",
      "Epoch: 426, Custo: 4.639\n",
      "Epoch: 427, Custo: 4.242\n",
      "Epoch: 428, Custo: 4.463\n",
      "Epoch: 429, Custo: 5.011\n",
      "Epoch: 430, Custo: 4.179\n",
      "Epoch: 431, Custo: 4.098\n",
      "Epoch: 432, Custo: 3.944\n",
      "Epoch: 433, Custo: 3.764\n",
      "Epoch: 434, Custo: 4.313\n",
      "Epoch: 435, Custo: 4.475\n",
      "Epoch: 436, Custo: 4.312\n",
      "Epoch: 437, Custo: 4.487\n",
      "Epoch: 438, Custo: 4.120\n",
      "Epoch: 439, Custo: 4.117\n",
      "Epoch: 440, Custo: 4.230\n",
      "Epoch: 441, Custo: 4.509\n",
      "Epoch: 442, Custo: 4.214\n",
      "Epoch: 443, Custo: 4.222\n",
      "Epoch: 444, Custo: 4.065\n",
      "Epoch: 445, Custo: 3.953\n",
      "Epoch: 446, Custo: 3.864\n",
      "Epoch: 447, Custo: 4.094\n",
      "Epoch: 448, Custo: 3.627\n",
      "Epoch: 449, Custo: 4.215\n",
      "Epoch: 450, Custo: 4.133\n",
      "Epoch: 451, Custo: 4.910\n",
      "Epoch: 452, Custo: 4.187\n",
      "Epoch: 453, Custo: 4.471\n",
      "Epoch: 454, Custo: 3.742\n",
      "Epoch: 455, Custo: 4.204\n",
      "Epoch: 456, Custo: 3.910\n",
      "Epoch: 457, Custo: 4.387\n",
      "Epoch: 458, Custo: 3.922\n",
      "Epoch: 459, Custo: 4.261\n",
      "Epoch: 460, Custo: 3.600\n",
      "Epoch: 461, Custo: 4.926\n",
      "Epoch: 462, Custo: 4.380\n",
      "Epoch: 463, Custo: 4.861\n",
      "Epoch: 464, Custo: 4.117\n",
      "Epoch: 465, Custo: 4.437\n",
      "Epoch: 466, Custo: 4.426\n",
      "Epoch: 467, Custo: 4.209\n",
      "Epoch: 468, Custo: 4.070\n",
      "Epoch: 469, Custo: 4.317\n",
      "Epoch: 470, Custo: 4.091\n",
      "Epoch: 471, Custo: 3.922\n",
      "Epoch: 472, Custo: 3.563\n",
      "Epoch: 473, Custo: 4.954\n",
      "Epoch: 474, Custo: 4.164\n",
      "Epoch: 475, Custo: 4.276\n",
      "Epoch: 476, Custo: 4.423\n",
      "Epoch: 477, Custo: 5.141\n",
      "Epoch: 478, Custo: 4.416\n",
      "Epoch: 479, Custo: 3.589\n",
      "Epoch: 480, Custo: 4.180\n",
      "Epoch: 481, Custo: 3.709\n",
      "Epoch: 482, Custo: 4.678\n",
      "Epoch: 483, Custo: 4.327\n",
      "Epoch: 484, Custo: 4.176\n",
      "Epoch: 485, Custo: 3.836\n",
      "Epoch: 486, Custo: 4.444\n",
      "Epoch: 487, Custo: 3.901\n",
      "Epoch: 488, Custo: 3.819\n",
      "Epoch: 489, Custo: 3.796\n",
      "Epoch: 490, Custo: 3.987\n",
      "Epoch: 491, Custo: 3.137\n",
      "Epoch: 492, Custo: 4.859\n",
      "Epoch: 493, Custo: 4.475\n",
      "Epoch: 494, Custo: 3.836\n",
      "Epoch: 495, Custo: 4.847\n",
      "Epoch: 496, Custo: 4.823\n",
      "Epoch: 497, Custo: 3.704\n",
      "Epoch: 498, Custo: 4.107\n",
      "Epoch: 499, Custo: 4.038\n",
      "Epoch: 500, Custo: 4.641\n",
      "Epoch: 501, Custo: 4.198\n",
      "Epoch: 502, Custo: 4.133\n",
      "Epoch: 503, Custo: 4.024\n",
      "Epoch: 504, Custo: 4.069\n",
      "Epoch: 505, Custo: 4.176\n",
      "Epoch: 506, Custo: 3.610\n",
      "Epoch: 507, Custo: 4.304\n",
      "Epoch: 508, Custo: 3.690\n",
      "Epoch: 509, Custo: 4.722\n",
      "Epoch: 510, Custo: 4.130\n",
      "Epoch: 511, Custo: 3.690\n",
      "Epoch: 512, Custo: 4.469\n",
      "Epoch: 513, Custo: 3.685\n",
      "Epoch: 514, Custo: 4.166\n",
      "Epoch: 515, Custo: 3.814\n",
      "Epoch: 516, Custo: 3.876\n",
      "Epoch: 517, Custo: 4.295\n",
      "Epoch: 518, Custo: 3.876\n",
      "Epoch: 519, Custo: 4.026\n",
      "Epoch: 520, Custo: 4.231\n",
      "Epoch: 521, Custo: 4.061\n",
      "Epoch: 522, Custo: 4.243\n",
      "Epoch: 523, Custo: 4.278\n",
      "Epoch: 524, Custo: 4.639\n",
      "Epoch: 525, Custo: 4.430\n",
      "Epoch: 526, Custo: 3.738\n",
      "Epoch: 527, Custo: 3.782\n",
      "Epoch: 528, Custo: 4.226\n",
      "Epoch: 529, Custo: 3.668\n",
      "Epoch: 530, Custo: 3.869\n",
      "Epoch: 531, Custo: 4.375\n",
      "Epoch: 532, Custo: 3.881\n",
      "Epoch: 533, Custo: 4.358\n",
      "Epoch: 534, Custo: 4.165\n",
      "Epoch: 535, Custo: 4.290\n",
      "Epoch: 536, Custo: 4.192\n",
      "Epoch: 537, Custo: 4.054\n",
      "Epoch: 538, Custo: 3.859\n",
      "Epoch: 539, Custo: 4.543\n",
      "Epoch: 540, Custo: 4.305\n",
      "Epoch: 541, Custo: 3.955\n",
      "Epoch: 542, Custo: 4.094\n",
      "Epoch: 543, Custo: 4.216\n",
      "Epoch: 544, Custo: 4.120\n",
      "Epoch: 545, Custo: 3.897\n",
      "Epoch: 546, Custo: 3.991\n",
      "Epoch: 547, Custo: 4.207\n",
      "Epoch: 548, Custo: 3.529\n",
      "Epoch: 549, Custo: 3.804\n",
      "Epoch: 550, Custo: 3.811\n",
      "Epoch: 551, Custo: 3.726\n",
      "Epoch: 552, Custo: 4.146\n",
      "Epoch: 553, Custo: 4.126\n",
      "Epoch: 554, Custo: 4.470\n",
      "Epoch: 555, Custo: 3.682\n",
      "Epoch: 556, Custo: 4.633\n",
      "Epoch: 557, Custo: 4.393\n",
      "Epoch: 558, Custo: 3.423\n",
      "Epoch: 559, Custo: 3.852\n",
      "Epoch: 560, Custo: 4.308\n",
      "Epoch: 561, Custo: 4.241\n",
      "Epoch: 562, Custo: 4.192\n",
      "Epoch: 563, Custo: 3.646\n",
      "Epoch: 564, Custo: 4.375\n",
      "Epoch: 565, Custo: 3.848\n",
      "Epoch: 566, Custo: 4.178\n",
      "Epoch: 567, Custo: 3.771\n",
      "Epoch: 568, Custo: 4.261\n",
      "Epoch: 569, Custo: 3.739\n",
      "Epoch: 570, Custo: 4.262\n",
      "Epoch: 571, Custo: 3.878\n",
      "Epoch: 572, Custo: 3.902\n",
      "Epoch: 573, Custo: 4.077\n",
      "Epoch: 574, Custo: 3.880\n",
      "Epoch: 575, Custo: 3.418\n",
      "Epoch: 576, Custo: 4.096\n",
      "Epoch: 577, Custo: 4.254\n",
      "Epoch: 578, Custo: 3.792\n",
      "Epoch: 579, Custo: 4.267\n",
      "Epoch: 580, Custo: 4.028\n",
      "Epoch: 581, Custo: 3.951\n",
      "Epoch: 582, Custo: 4.066\n",
      "Epoch: 583, Custo: 3.369\n",
      "Epoch: 584, Custo: 4.029\n",
      "Epoch: 585, Custo: 3.683\n",
      "Epoch: 586, Custo: 4.232\n",
      "Epoch: 587, Custo: 4.052\n",
      "Epoch: 588, Custo: 4.217\n",
      "Epoch: 589, Custo: 4.009\n",
      "Epoch: 590, Custo: 4.029\n",
      "Epoch: 591, Custo: 3.749\n",
      "Epoch: 592, Custo: 4.062\n",
      "Epoch: 593, Custo: 4.136\n",
      "Epoch: 594, Custo: 3.478\n",
      "Epoch: 595, Custo: 4.255\n",
      "Epoch: 596, Custo: 4.581\n",
      "Epoch: 597, Custo: 3.889\n",
      "Epoch: 598, Custo: 4.269\n",
      "Epoch: 599, Custo: 3.943\n",
      "Epoch: 600, Custo: 4.360\n",
      "Epoch: 601, Custo: 3.720\n",
      "Epoch: 602, Custo: 3.967\n",
      "Epoch: 603, Custo: 3.703\n",
      "Epoch: 604, Custo: 3.605\n",
      "Epoch: 605, Custo: 3.925\n",
      "Epoch: 606, Custo: 4.065\n",
      "Epoch: 607, Custo: 3.821\n",
      "Epoch: 608, Custo: 3.797\n",
      "Epoch: 609, Custo: 3.825\n",
      "Epoch: 610, Custo: 3.723\n",
      "Epoch: 611, Custo: 4.014\n",
      "Epoch: 612, Custo: 3.746\n",
      "Epoch: 613, Custo: 3.405\n",
      "Epoch: 614, Custo: 3.729\n",
      "Epoch: 615, Custo: 4.185\n",
      "Epoch: 616, Custo: 3.645\n",
      "Epoch: 617, Custo: 4.111\n",
      "Epoch: 618, Custo: 4.123\n",
      "Epoch: 619, Custo: 3.565\n",
      "Epoch: 620, Custo: 3.603\n",
      "Epoch: 621, Custo: 3.787\n",
      "Epoch: 622, Custo: 3.269\n",
      "Epoch: 623, Custo: 3.899\n",
      "Epoch: 624, Custo: 3.864\n",
      "Epoch: 625, Custo: 4.091\n",
      "Epoch: 626, Custo: 3.890\n",
      "Epoch: 627, Custo: 3.846\n",
      "Epoch: 628, Custo: 3.907\n",
      "Epoch: 629, Custo: 3.904\n",
      "Epoch: 630, Custo: 3.865\n",
      "Epoch: 631, Custo: 4.390\n",
      "Epoch: 632, Custo: 3.634\n",
      "Epoch: 633, Custo: 4.249\n",
      "Epoch: 634, Custo: 4.158\n",
      "Epoch: 635, Custo: 3.899\n",
      "Epoch: 636, Custo: 3.954\n",
      "Epoch: 637, Custo: 4.007\n",
      "Epoch: 638, Custo: 4.420\n",
      "Epoch: 639, Custo: 3.726\n",
      "Epoch: 640, Custo: 4.012\n",
      "Epoch: 641, Custo: 3.784\n",
      "Epoch: 642, Custo: 4.298\n",
      "Epoch: 643, Custo: 4.180\n",
      "Epoch: 644, Custo: 3.876\n",
      "Epoch: 645, Custo: 3.781\n",
      "Epoch: 646, Custo: 4.296\n",
      "Epoch: 647, Custo: 3.882\n",
      "Epoch: 648, Custo: 4.312\n",
      "Epoch: 649, Custo: 3.755\n",
      "Epoch: 650, Custo: 3.725\n",
      "Epoch: 651, Custo: 4.319\n",
      "Epoch: 652, Custo: 3.703\n",
      "Epoch: 653, Custo: 3.475\n",
      "Epoch: 654, Custo: 3.570\n",
      "Epoch: 655, Custo: 4.361\n",
      "Epoch: 656, Custo: 3.696\n",
      "Epoch: 657, Custo: 3.653\n",
      "Epoch: 658, Custo: 3.743\n",
      "Epoch: 659, Custo: 3.978\n",
      "Epoch: 660, Custo: 3.753\n",
      "Epoch: 661, Custo: 3.662\n",
      "Epoch: 662, Custo: 3.851\n",
      "Epoch: 663, Custo: 3.764\n",
      "Epoch: 664, Custo: 3.728\n",
      "Epoch: 665, Custo: 4.032\n",
      "Epoch: 666, Custo: 3.789\n",
      "Epoch: 667, Custo: 3.242\n",
      "Epoch: 668, Custo: 3.620\n",
      "Epoch: 669, Custo: 3.717\n",
      "Epoch: 670, Custo: 3.439\n",
      "Epoch: 671, Custo: 3.880\n",
      "Epoch: 672, Custo: 4.298\n",
      "Epoch: 673, Custo: 3.465\n",
      "Epoch: 674, Custo: 3.488\n",
      "Epoch: 675, Custo: 3.731\n",
      "Epoch: 676, Custo: 3.788\n",
      "Epoch: 677, Custo: 3.996\n",
      "Epoch: 678, Custo: 3.576\n",
      "Epoch: 679, Custo: 4.019\n",
      "Epoch: 680, Custo: 4.131\n",
      "Epoch: 681, Custo: 4.114\n",
      "Epoch: 682, Custo: 3.676\n",
      "Epoch: 683, Custo: 3.841\n",
      "Epoch: 684, Custo: 3.872\n",
      "Epoch: 685, Custo: 3.950\n",
      "Epoch: 686, Custo: 3.921\n",
      "Epoch: 687, Custo: 3.720\n",
      "Epoch: 688, Custo: 3.219\n",
      "Epoch: 689, Custo: 3.794\n",
      "Epoch: 690, Custo: 3.689\n",
      "Epoch: 691, Custo: 3.911\n",
      "Epoch: 692, Custo: 3.216\n",
      "Epoch: 693, Custo: 3.452\n",
      "Epoch: 694, Custo: 3.668\n",
      "Epoch: 695, Custo: 4.094\n",
      "Epoch: 696, Custo: 3.822\n",
      "Epoch: 697, Custo: 4.116\n",
      "Epoch: 698, Custo: 3.586\n",
      "Epoch: 699, Custo: 3.352\n",
      "Epoch: 700, Custo: 3.889\n",
      "Epoch: 701, Custo: 4.177\n",
      "Epoch: 702, Custo: 4.268\n",
      "Epoch: 703, Custo: 3.172\n",
      "Epoch: 704, Custo: 3.543\n",
      "Epoch: 705, Custo: 3.542\n",
      "Epoch: 706, Custo: 3.394\n",
      "Epoch: 707, Custo: 3.722\n",
      "Epoch: 708, Custo: 3.376\n",
      "Epoch: 709, Custo: 3.987\n",
      "Epoch: 710, Custo: 3.766\n",
      "Epoch: 711, Custo: 3.261\n",
      "Epoch: 712, Custo: 3.144\n",
      "Epoch: 713, Custo: 3.416\n",
      "Epoch: 714, Custo: 4.012\n",
      "Epoch: 715, Custo: 3.462\n",
      "Epoch: 716, Custo: 3.430\n",
      "Epoch: 717, Custo: 3.569\n",
      "Epoch: 718, Custo: 3.735\n",
      "Epoch: 719, Custo: 3.576\n",
      "Epoch: 720, Custo: 3.384\n",
      "Epoch: 721, Custo: 3.627\n",
      "Epoch: 722, Custo: 3.836\n",
      "Epoch: 723, Custo: 3.605\n",
      "Epoch: 724, Custo: 3.256\n",
      "Epoch: 725, Custo: 3.754\n",
      "Epoch: 726, Custo: 3.558\n",
      "Epoch: 727, Custo: 3.448\n",
      "Epoch: 728, Custo: 4.078\n",
      "Epoch: 729, Custo: 4.392\n",
      "Epoch: 730, Custo: 3.158\n",
      "Epoch: 731, Custo: 3.416\n",
      "Epoch: 732, Custo: 3.826\n",
      "Epoch: 733, Custo: 3.765\n",
      "Epoch: 734, Custo: 3.362\n",
      "Epoch: 735, Custo: 3.747\n",
      "Epoch: 736, Custo: 3.728\n",
      "Epoch: 737, Custo: 3.743\n",
      "Epoch: 738, Custo: 3.766\n",
      "Epoch: 739, Custo: 3.815\n",
      "Epoch: 740, Custo: 3.707\n",
      "Epoch: 741, Custo: 3.779\n",
      "Epoch: 742, Custo: 4.123\n",
      "Epoch: 743, Custo: 3.174\n",
      "Epoch: 744, Custo: 4.067\n",
      "Epoch: 745, Custo: 3.802\n",
      "Epoch: 746, Custo: 3.235\n",
      "Epoch: 747, Custo: 3.838\n",
      "Epoch: 748, Custo: 3.535\n",
      "Epoch: 749, Custo: 3.701\n",
      "Epoch: 750, Custo: 3.577\n",
      "Epoch: 751, Custo: 3.557\n",
      "Epoch: 752, Custo: 3.744\n",
      "Epoch: 753, Custo: 3.560\n",
      "Epoch: 754, Custo: 3.543\n",
      "Epoch: 755, Custo: 3.106\n",
      "Epoch: 756, Custo: 3.435\n",
      "Epoch: 757, Custo: 3.705\n",
      "Epoch: 758, Custo: 3.827\n",
      "Epoch: 759, Custo: 3.569\n",
      "Epoch: 760, Custo: 3.631\n",
      "Epoch: 761, Custo: 3.902\n",
      "Epoch: 762, Custo: 3.329\n",
      "Epoch: 763, Custo: 3.842\n",
      "Epoch: 764, Custo: 3.748\n",
      "Epoch: 765, Custo: 3.331\n",
      "Epoch: 766, Custo: 3.247\n",
      "Epoch: 767, Custo: 4.229\n",
      "Epoch: 768, Custo: 3.686\n",
      "Epoch: 769, Custo: 3.363\n",
      "Epoch: 770, Custo: 3.728\n",
      "Epoch: 771, Custo: 3.803\n",
      "Epoch: 772, Custo: 3.365\n",
      "Epoch: 773, Custo: 3.631\n",
      "Epoch: 774, Custo: 3.517\n",
      "Epoch: 775, Custo: 3.645\n",
      "Epoch: 776, Custo: 3.584\n",
      "Epoch: 777, Custo: 3.469\n",
      "Epoch: 778, Custo: 3.261\n",
      "Epoch: 779, Custo: 3.183\n",
      "Epoch: 780, Custo: 3.447\n",
      "Epoch: 781, Custo: 3.305\n",
      "Epoch: 782, Custo: 3.730\n",
      "Epoch: 783, Custo: 3.611\n",
      "Epoch: 784, Custo: 3.869\n",
      "Epoch: 785, Custo: 3.283\n",
      "Epoch: 786, Custo: 3.557\n",
      "Epoch: 787, Custo: 3.151\n",
      "Epoch: 788, Custo: 3.961\n",
      "Epoch: 789, Custo: 3.698\n",
      "Epoch: 790, Custo: 3.550\n",
      "Epoch: 791, Custo: 3.308\n",
      "Epoch: 792, Custo: 3.706\n",
      "Epoch: 793, Custo: 3.826\n",
      "Epoch: 794, Custo: 3.528\n",
      "Epoch: 795, Custo: 3.684\n",
      "Epoch: 796, Custo: 3.564\n",
      "Epoch: 797, Custo: 3.400\n",
      "Epoch: 798, Custo: 3.301\n",
      "Epoch: 799, Custo: 3.714\n",
      "Epoch: 800, Custo: 3.160\n",
      "Epoch: 801, Custo: 3.577\n",
      "Epoch: 802, Custo: 3.560\n",
      "Epoch: 803, Custo: 3.513\n",
      "Epoch: 804, Custo: 3.434\n",
      "Epoch: 805, Custo: 3.961\n",
      "Epoch: 806, Custo: 3.699\n",
      "Epoch: 807, Custo: 3.751\n",
      "Epoch: 808, Custo: 3.418\n",
      "Epoch: 809, Custo: 3.192\n",
      "Epoch: 810, Custo: 3.508\n",
      "Epoch: 811, Custo: 3.485\n",
      "Epoch: 812, Custo: 3.654\n",
      "Epoch: 813, Custo: 3.516\n",
      "Epoch: 814, Custo: 3.290\n",
      "Epoch: 815, Custo: 3.354\n",
      "Epoch: 816, Custo: 3.571\n",
      "Epoch: 817, Custo: 3.310\n",
      "Epoch: 818, Custo: 3.498\n",
      "Epoch: 819, Custo: 3.734\n",
      "Epoch: 820, Custo: 3.567\n",
      "Epoch: 821, Custo: 3.336\n",
      "Epoch: 822, Custo: 3.792\n",
      "Epoch: 823, Custo: 3.567\n",
      "Epoch: 824, Custo: 3.193\n",
      "Epoch: 825, Custo: 3.665\n",
      "Epoch: 826, Custo: 3.129\n",
      "Epoch: 827, Custo: 4.244\n",
      "Epoch: 828, Custo: 3.073\n",
      "Epoch: 829, Custo: 3.217\n",
      "Epoch: 830, Custo: 3.115\n",
      "Epoch: 831, Custo: 3.317\n",
      "Epoch: 832, Custo: 3.794\n",
      "Epoch: 833, Custo: 3.703\n",
      "Epoch: 834, Custo: 3.633\n",
      "Epoch: 835, Custo: 3.728\n",
      "Epoch: 836, Custo: 3.153\n",
      "Epoch: 837, Custo: 3.450\n",
      "Epoch: 838, Custo: 3.451\n",
      "Epoch: 839, Custo: 3.716\n",
      "Epoch: 840, Custo: 3.598\n",
      "Epoch: 841, Custo: 3.822\n",
      "Epoch: 842, Custo: 3.210\n",
      "Epoch: 843, Custo: 3.566\n",
      "Epoch: 844, Custo: 3.373\n",
      "Epoch: 845, Custo: 3.491\n",
      "Epoch: 846, Custo: 3.158\n",
      "Epoch: 847, Custo: 3.676\n",
      "Epoch: 848, Custo: 3.322\n",
      "Epoch: 849, Custo: 3.231\n",
      "Epoch: 850, Custo: 3.199\n",
      "Epoch: 851, Custo: 3.353\n",
      "Epoch: 852, Custo: 3.641\n",
      "Epoch: 853, Custo: 3.168\n",
      "Epoch: 854, Custo: 3.292\n",
      "Epoch: 855, Custo: 3.916\n",
      "Epoch: 856, Custo: 3.422\n",
      "Epoch: 857, Custo: 3.993\n",
      "Epoch: 858, Custo: 3.623\n",
      "Epoch: 859, Custo: 4.134\n",
      "Epoch: 860, Custo: 3.059\n",
      "Epoch: 861, Custo: 3.345\n",
      "Epoch: 862, Custo: 3.300\n",
      "Epoch: 863, Custo: 2.837\n",
      "Epoch: 864, Custo: 3.514\n",
      "Epoch: 865, Custo: 3.324\n",
      "Epoch: 866, Custo: 3.912\n",
      "Epoch: 867, Custo: 3.680\n",
      "Epoch: 868, Custo: 4.132\n",
      "Epoch: 869, Custo: 3.103\n",
      "Epoch: 870, Custo: 3.056\n",
      "Epoch: 871, Custo: 3.930\n",
      "Epoch: 872, Custo: 3.144\n",
      "Epoch: 873, Custo: 3.187\n",
      "Epoch: 874, Custo: 3.394\n",
      "Epoch: 875, Custo: 3.720\n",
      "Epoch: 876, Custo: 3.348\n",
      "Epoch: 877, Custo: 4.103\n",
      "Epoch: 878, Custo: 3.953\n",
      "Epoch: 879, Custo: 3.451\n",
      "Epoch: 880, Custo: 3.251\n",
      "Epoch: 881, Custo: 2.925\n",
      "Epoch: 882, Custo: 3.213\n",
      "Epoch: 883, Custo: 3.001\n",
      "Epoch: 884, Custo: 3.282\n",
      "Epoch: 885, Custo: 3.157\n",
      "Epoch: 886, Custo: 3.468\n",
      "Epoch: 887, Custo: 3.406\n",
      "Epoch: 888, Custo: 3.173\n",
      "Epoch: 889, Custo: 3.587\n",
      "Epoch: 890, Custo: 3.739\n",
      "Epoch: 891, Custo: 3.509\n",
      "Epoch: 892, Custo: 3.088\n",
      "Epoch: 893, Custo: 3.387\n",
      "Epoch: 894, Custo: 3.572\n",
      "Epoch: 895, Custo: 3.255\n",
      "Epoch: 896, Custo: 3.444\n",
      "Epoch: 897, Custo: 3.682\n",
      "Epoch: 898, Custo: 3.560\n",
      "Epoch: 899, Custo: 3.676\n",
      "Epoch: 900, Custo: 3.780\n",
      "Epoch: 901, Custo: 2.923\n",
      "Epoch: 902, Custo: 3.372\n",
      "Epoch: 903, Custo: 3.317\n",
      "Epoch: 904, Custo: 3.274\n",
      "Epoch: 905, Custo: 2.988\n",
      "Epoch: 906, Custo: 3.094\n",
      "Epoch: 907, Custo: 3.230\n",
      "Epoch: 908, Custo: 3.520\n",
      "Epoch: 909, Custo: 3.840\n",
      "Epoch: 910, Custo: 3.891\n",
      "Epoch: 911, Custo: 3.087\n",
      "Epoch: 912, Custo: 3.271\n",
      "Epoch: 913, Custo: 3.145\n",
      "Epoch: 914, Custo: 3.515\n",
      "Epoch: 915, Custo: 3.541\n",
      "Epoch: 916, Custo: 3.668\n",
      "Epoch: 917, Custo: 3.254\n",
      "Epoch: 918, Custo: 3.414\n",
      "Epoch: 919, Custo: 3.379\n",
      "Epoch: 920, Custo: 3.141\n",
      "Epoch: 921, Custo: 3.594\n",
      "Epoch: 922, Custo: 3.065\n",
      "Epoch: 923, Custo: 2.987\n",
      "Epoch: 924, Custo: 3.245\n",
      "Epoch: 925, Custo: 3.804\n",
      "Epoch: 926, Custo: 3.159\n",
      "Epoch: 927, Custo: 3.692\n",
      "Epoch: 928, Custo: 3.415\n",
      "Epoch: 929, Custo: 3.808\n",
      "Epoch: 930, Custo: 3.684\n",
      "Epoch: 931, Custo: 3.141\n",
      "Epoch: 932, Custo: 3.177\n",
      "Epoch: 933, Custo: 3.240\n",
      "Epoch: 934, Custo: 3.426\n",
      "Epoch: 935, Custo: 3.167\n",
      "Epoch: 936, Custo: 3.405\n",
      "Epoch: 937, Custo: 3.593\n",
      "Epoch: 938, Custo: 3.301\n",
      "Epoch: 939, Custo: 3.880\n",
      "Epoch: 940, Custo: 3.536\n",
      "Epoch: 941, Custo: 3.186\n",
      "Epoch: 942, Custo: 3.628\n",
      "Epoch: 943, Custo: 3.298\n",
      "Epoch: 944, Custo: 3.160\n",
      "Epoch: 945, Custo: 3.304\n",
      "Epoch: 946, Custo: 3.242\n",
      "Epoch: 947, Custo: 3.469\n",
      "Epoch: 948, Custo: 3.477\n",
      "Epoch: 949, Custo: 3.807\n",
      "Epoch: 950, Custo: 3.371\n",
      "Epoch: 951, Custo: 3.544\n",
      "Epoch: 952, Custo: 3.315\n",
      "Epoch: 953, Custo: 3.285\n",
      "Epoch: 954, Custo: 3.055\n",
      "Epoch: 955, Custo: 2.961\n",
      "Epoch: 956, Custo: 3.128\n",
      "Epoch: 957, Custo: 2.858\n",
      "Epoch: 958, Custo: 3.188\n",
      "Epoch: 959, Custo: 3.064\n",
      "Epoch: 960, Custo: 3.253\n",
      "Epoch: 961, Custo: 3.618\n",
      "Epoch: 962, Custo: 3.249\n",
      "Epoch: 963, Custo: 3.113\n",
      "Epoch: 964, Custo: 3.394\n",
      "Epoch: 965, Custo: 3.143\n",
      "Epoch: 966, Custo: 3.103\n",
      "Epoch: 967, Custo: 2.969\n",
      "Epoch: 968, Custo: 3.448\n",
      "Epoch: 969, Custo: 3.386\n",
      "Epoch: 970, Custo: 3.523\n",
      "Epoch: 971, Custo: 3.202\n",
      "Epoch: 972, Custo: 2.565\n",
      "Epoch: 973, Custo: 3.523\n",
      "Epoch: 974, Custo: 3.414\n",
      "Epoch: 975, Custo: 3.381\n",
      "Epoch: 976, Custo: 3.740\n",
      "Epoch: 977, Custo: 3.786\n",
      "Epoch: 978, Custo: 2.908\n",
      "Epoch: 979, Custo: 3.335\n",
      "Epoch: 980, Custo: 3.198\n",
      "Epoch: 981, Custo: 3.203\n",
      "Epoch: 982, Custo: 3.539\n",
      "Epoch: 983, Custo: 3.330\n",
      "Epoch: 984, Custo: 3.269\n",
      "Epoch: 985, Custo: 3.291\n",
      "Epoch: 986, Custo: 3.611\n",
      "Epoch: 987, Custo: 3.458\n",
      "Epoch: 988, Custo: 3.698\n",
      "Epoch: 989, Custo: 3.129\n",
      "Epoch: 990, Custo: 3.555\n",
      "Epoch: 991, Custo: 3.380\n",
      "Epoch: 992, Custo: 3.360\n",
      "Epoch: 993, Custo: 3.151\n",
      "Epoch: 994, Custo: 3.117\n",
      "Epoch: 995, Custo: 3.147\n",
      "Epoch: 996, Custo: 3.237\n",
      "Epoch: 997, Custo: 3.242\n",
      "Epoch: 998, Custo: 3.279\n",
      "Epoch: 999, Custo: 2.965\n",
      "Epoch: 1000, Custo: 3.439\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "\n",
    "# Carrega os dados\n",
    "data = load_boston()\n",
    "\n",
    "# Variáveis de entrada e saída para treinamento supervisionado\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "# Normaliza os dados\n",
    "X_ = (X_ - np.mean(X_, axis = 0)) / np.std(X_, axis = 0)\n",
    "\n",
    "# Número de features e número de neurônios\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "\n",
    "# Define valores randômicos para inicializar pesos e bias\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Rede Neural\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "# Define o feed_dict\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "# Número de epochs (altere esse valor para ver as mudanças no resultado)\n",
    "epochs = 1000\n",
    "\n",
    "# Número total de exemplos\n",
    "m = X_.shape[0]\n",
    "\n",
    "# Batch size\n",
    "batch_size = 11\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "# Define o grafo computacional\n",
    "graph = topological_sort(feed_dict)\n",
    "\n",
    "# Valores que serão aprendidos pela rede\n",
    "params = [W1, b1, W2, b2]\n",
    "\n",
    "# Número total de exemplos\n",
    "print(\"Número Total de Exemplos = {}\".format(m))\n",
    "\n",
    "# Treinamento do modelo\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        \n",
    "        # Passo 1 - Testa aleatoriamente um lote de exemplos\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples = batch_size)\n",
    "\n",
    "        # Reset dos valores de X e y \n",
    "        X.valor = X_batch\n",
    "        y.valor = y_batch\n",
    "\n",
    "        # Passo 2 - Forward e Backpropagation\n",
    "        forward_and_backward(graph)\n",
    "\n",
    "        # Passo 3 - Otimização por SGD\n",
    "        sgd_update(params)\n",
    "\n",
    "        loss += graph[-1].valor\n",
    "\n",
    "    print(\"Epoch: {}, Custo: {:.3f}\".format(i+1, loss/steps_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}